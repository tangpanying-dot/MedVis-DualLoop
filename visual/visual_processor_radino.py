# visual/visual_processor.py
"""
RAD-DINO ç‰¹å¾æå–å™¨ (æœ€ç»ˆä¼˜åŒ–ç‰ˆ)

æ ¸å¿ƒç‰¹æ€§:
1. ä½¿ç”¨ RadDinoVisualEncoder æå– (1369, 768) ç½‘æ ¼ç‰¹å¾ (37x37 grid @ 518px)
2. å¤šè§†è§’æ‹¼æ¥ï¼šåŒä¸€ Study çš„å¤šå¼ å›¾ç‰‡ç‰¹å¾æ²¿åºåˆ—ç»´åº¦æ‹¼æ¥ -> (N*1369, 768)
3. MAX_VIEWS=4 é™åˆ¶ï¼šè¦†ç›–99.93%æ ·æœ¬ï¼Œä¼˜åŒ–è®­ç»ƒæ•ˆç‡
4. æ–­ç‚¹ç»­ä¼ ï¼šè‡ªåŠ¨è·³è¿‡å·²æå–çš„study
5. å†…å­˜ä¼˜åŒ–ï¼šBuffer æœºåˆ¶æµå¼å¤„ç†ï¼Œé˜²æ­¢ OOM
6. è·¯å¾„å…¼å®¹ï¼šè‡ªåŠ¨å¤„ç† files/å’Œimages/å‰ç¼€

ç‰ˆæœ¬: v1.0 Final
æ—¥æœŸ: 2025-11-29
"""

import pandas as pd
import json
import os
from tqdm import tqdm
import numpy as np
import torch
from torch.utils.data import Dataset, DataLoader
from collections import defaultdict
import argparse

# HuggingFaceé•œåƒåŠ é€Ÿ
os.environ["HF_ENDPOINT"] = "https://hf-mirror.com"

# å¯¼å…¥ RAD-DINO Encoder
from visual.visual_encoder_raddino import RadDinoVisualEncoder


class MimicCxrDatasetRadDino(Dataset):
    """
    MIMIC-CXR æ•°æ®é›†åŠ è½½å™¨ (RAD-DINO é€‚é…ç‰ˆ)
    
    åŠŸèƒ½:
    - å¤ç”¨ Encoder çš„é¢„å¤„ç†æ–¹æ³•ç¡®ä¿ä¸€è‡´æ€§
    - æ”¯æŒæ–­ç‚¹ç»­ä¼ ï¼ˆè·³è¿‡å·²å®Œæˆçš„studyï¼‰
    - å…¼å®¹å¤šç§è·¯å¾„æ ¼å¼
    """
    def __init__(self, df, image_root, encoder_instance, existing_studies=None):
        self.samples = []
        self.encoder = encoder_instance 
        self.existing_studies = existing_studies or set()
        
        print("æ­£åœ¨è§£ææ•°æ®é›†è·¯å¾„...")
        skipped_existing = 0
        skipped_error = 0
        
        for idx, row in df.iterrows():
            study_id = str(row['study_id'])
            
            # âœ… æ–­ç‚¹ç»­ä¼ ï¼šè·³è¿‡å·²å­˜åœ¨çš„study
            if study_id in self.existing_studies:
                skipped_existing += 1
                continue
            
            try:
                # å…¼å®¹JSONå­—ç¬¦ä¸²æˆ–åˆ—è¡¨
                image_paths = json.loads(row['image_paths']) if isinstance(row['image_paths'], str) else row['image_paths']
                views = json.loads(row['view_positions']) if isinstance(row['view_positions'], str) else row['view_positions']
            except Exception as e:
                skipped_error += 1
                continue 

            # ç¡®ä¿è·¯å¾„å’Œè§†è§’æ•°é‡å¯¹é½
            if len(image_paths) != len(views):
                skipped_error += 1
                continue
            
            for img_path, view in zip(image_paths, views):
                # âœ… è·¯å¾„æ¸…æ´—ï¼šå…¼å®¹å¤šç§æ ¼å¼
                # æ”¯æŒ: files/p10/.../*.dcm æˆ– images/p10/.../*.jpg
                
                # 1. å»æ‰å‰ç¼€ (files/ æˆ– images/)
                if img_path.startswith("files/"):
                    path_segment = img_path.replace("files/", "", 1)
                elif img_path.startswith("images/"):
                    path_segment = img_path.replace("images/", "", 1)
                else:
                    path_segment = img_path
                
                # 2. æ›¿æ¢æ‰©å±•å .dcm -> .jpg
                if path_segment.endswith(".dcm"):
                    path_segment = os.path.splitext(path_segment)[0] + ".jpg"
                
                # 3. æ„å»ºå®Œæ•´è·¯å¾„
                # image_root å·²ç»æ˜¯ data/mimic-cxr/images
                full_path = os.path.join(image_root, path_segment)
                
                self.samples.append({
                    'study_id': study_id,
                    'image_path': full_path,
                    'view': view
                })
        
        # ç»Ÿè®¡ä¿¡æ¯
        if skipped_existing > 0:
            print(f"âœ… è·³è¿‡å·²å­˜åœ¨çš„study: {skipped_existing} ä¸ª")
        if skipped_error > 0:
            print(f"âš ï¸  è·³è¿‡è§£æé”™è¯¯çš„è¡Œ: {skipped_error} ä¸ª")
        print(f"ğŸ“Š å¾…å¤„ç†å›¾ç‰‡æ€»æ•°: {len(self.samples)}")
    
    def __len__(self):
        return len(self.samples)
    
    def __getitem__(self, idx):
        sample = self.samples[idx]
        
        # ä½¿ç”¨ Encoder çš„æ ‡å‡†é¢„å¤„ç†
        # è¿”å›: (3, 518, 518) tensor
        img_tensor = self.encoder.preprocess_image(sample['image_path'])
        
        success = img_tensor is not None
        
        return {
            'study_id': sample['study_id'],
            'image_tensor': img_tensor, 
            'view': sample['view'],
            'image_path': sample['image_path'],
            'success': success
        }


def collate_fn(batch):
    """è¿‡æ»¤å¤±è´¥çš„æ ·æœ¬"""
    return [b for b in batch if b is not None and b['success']]


def process_batch_raddino(encoder, batch_samples):
    """
    RAD-DINO æ‰¹å¤„ç†æå–
    
    Args:
        encoder: RadDinoVisualEncoder å®ä¾‹
        batch_samples: æ‰¹æ¬¡æ ·æœ¬åˆ—è¡¨
        
    Returns:
        features_by_study: {study_id: [{'features': tensor, 'view': str}, ...]}
    """
    features_by_study = defaultdict(list)
    
    batch_tensors = []
    valid_samples = []
    
    # 1. æ”¶é›†æœ‰æ•ˆæ ·æœ¬
    for sample in batch_samples:
        if sample['success'] and sample['image_tensor'] is not None:
            batch_tensors.append(sample['image_tensor'])
            valid_samples.append(sample)
    
    if not batch_tensors:
        return features_by_study
    
    # 2. æ‰¹é‡æå–ç‰¹å¾
    # Input:  (B, 3, 518, 518)
    # Output: (B, 1369, 768)
    batch_input = torch.stack(batch_tensors, dim=0)
    batch_features = encoder.extract_features_batch(batch_input)
    
    # 3. åˆ†é…åˆ°å„study
    for i, sample in enumerate(valid_samples):
        study_id = sample['study_id']
        view = sample['view']
        
        features_by_study[study_id].append({
            'features': batch_features[i].cpu(),  # è½¬CPUé‡Šæ”¾æ˜¾å­˜
            'view': view
        })
    
    return features_by_study


def concat_study_features(feature_view_list):
    """
    æ‹¼æ¥åŒä¸€ Study çš„å¤šè§†è§’ç‰¹å¾
    
    æ ¸å¿ƒé€»è¾‘:
    1. æŒ‰ä¼˜å…ˆçº§æ’åºè§†è§’ (PA -> AP -> LATERAL -> LL -> å…¶ä»–)
    2. é™åˆ¶æœ€å¤§è§†è§’æ•°=4 (è¦†ç›–99.93%æ ·æœ¬)
    3. æ²¿åºåˆ—ç»´åº¦æ‹¼æ¥ç‰¹å¾
    
    Args:
        feature_view_list: [{'features': (1369,768), 'view': str}, ...]
        
    Returns:
        concat_features: (N*1369, 768) tensor
        metadata: dict with num_views, total_tokens, etc.
    """
    if not feature_view_list:
        return None, None
    
    # 1. è§†è§’ä¼˜å…ˆçº§æ’åº
    view_order = ['PA', 'AP', 'LATERAL', 'LL']
    
    def get_sort_key(x):
        view_val = x['view']
        view_str = str(view_val) if view_val is not None else ""
        view_upper = view_str.upper()
        if view_upper in view_order:
            return view_order.index(view_upper)
        return 999

    sorted_items = sorted(feature_view_list, key=get_sort_key)
    
    # 2. âœ… é™åˆ¶æœ€å¤§è§†è§’æ•°
    MAX_VIEWS = 4  # è¦†ç›–99.93%æ ·æœ¬ï¼Œå¹³è¡¡æ•ˆç‡ä¸è¦†ç›–ç‡
    
    original_num_views = len(sorted_items)
    if len(sorted_items) > MAX_VIEWS:
        # ä¿ç•™ä¼˜å…ˆçº§æœ€é«˜çš„å‰4ä¸ªè§†è§’
        sorted_items = sorted_items[:MAX_VIEWS]
    
    # 3. æå–ç‰¹å¾å’Œè§†è§’åˆ—è¡¨
    features_list = [item['features'] for item in sorted_items]
    views_list = [str(item['view']) for item in sorted_items]
    
    # 4. æ‹¼æ¥ç‰¹å¾
    # å•è§†è§’: (1369, 768)
    # å¤šè§†è§’: (N*1369, 768) æ²¿dim=0æ‹¼æ¥
    concat_features = torch.cat(features_list, dim=0)
    
    # 5. ç”Ÿæˆå…ƒæ•°æ®
    metadata = {
        'num_views': len(views_list),              # å®é™…ä½¿ç”¨çš„è§†è§’æ•°
        'original_num_views': original_num_views,  # åŸå§‹è§†è§’æ•°
        'total_tokens': concat_features.shape[0],  # æ€»tokenæ•° = N*1369
        'views': views_list,                       # è§†è§’åˆ—è¡¨
        'patch_size': 1369,                        # æ¯ä¸ªè§†è§’çš„patchæ•°
        'feature_dim': 768,                        # RAD-DINOç‰¹å¾ç»´åº¦
        'truncated': original_num_views > MAX_VIEWS  # æ˜¯å¦è¢«æˆªæ–­
    }
    
    return concat_features, metadata


def scan_existing_features(output_dir):
    """
    æ‰«æå·²å­˜åœ¨çš„ç‰¹å¾æ–‡ä»¶ï¼Œæ”¯æŒæ–­ç‚¹ç»­ä¼ 
    
    Returns:
        existing_studies: set of study_ids (str)
    """
    if not os.path.exists(output_dir):
        return set()
    
    existing_files = os.listdir(output_dir)
    existing_studies = set([
        f.replace('.npy', '') 
        for f in existing_files 
        if f.endswith('.npy')
    ])
    return existing_studies


def main(args):
    print("=" * 80)
    print("RAD-DINO ç‰¹å¾æå–å™¨ (Final Optimized Version)")
    print("=" * 80)
    print(f"é…ç½®:")
    print(f"  åˆ†è¾¨ç‡: 518x518")
    print(f"  ç‰¹å¾ç»´åº¦: (1369, 768) per view")
    print(f"  æœ€å¤§è§†è§’æ•°: 4 (è¦†ç›–99.93%)")
    print(f"  å­˜å‚¨æ ¼å¼: float16")
    print("=" * 80)
    
    # è¾“å‡ºç›®å½•
    output_dir = os.path.join(args.output_dir, "rad_dino")
    os.makedirs(output_dir, exist_ok=True)
    
    # âœ… æ–­ç‚¹ç»­ä¼ ï¼šæ‰«æå·²å­˜åœ¨çš„ç‰¹å¾
    print(f"\nğŸ” æ‰«æå·²å­˜åœ¨çš„ç‰¹å¾æ–‡ä»¶...")
    existing_studies = scan_existing_features(output_dir)
    if existing_studies:
        print(f"âœ… æ‰¾åˆ° {len(existing_studies)} ä¸ªå·²å®Œæˆçš„study (å°†è‡ªåŠ¨è·³è¿‡)")
    else:
        print(f"ğŸ“ æœªæ‰¾åˆ°å·²å­˜åœ¨ç‰¹å¾ï¼Œå°†ä»å¤´å¼€å§‹")
    
    # 1. åˆå§‹åŒ– Encoder
    print(f"\n1. åˆå§‹åŒ– RAD-DINO Encoder...")
    print(f"   æ¨¡å‹: {args.model_name}")
    encoder = RadDinoVisualEncoder(model_name=args.model_name)
    
    # 2. åŠ è½½æ•°æ®é›†
    print(f"\n2. åŠ è½½æ•°æ®é›†...")
    print(f"   CSV: {args.csv_file}")
    df = pd.read_csv(args.csv_file)
    
    # æŒ‰ study_id æ’åºï¼ˆæµå¼Bufferéœ€è¦ï¼‰
    print("   æ­£åœ¨æŒ‰ study_id æ’åº...")
    df = df.sort_values('study_id')
    
    # åˆ›å»ºæ•°æ®é›†
    dataset = MimicCxrDatasetRadDino(
        df, 
        args.image_root, 
        encoder,
        existing_studies=existing_studies
    )
    
    if len(dataset) == 0:
        print("\nâœ… æ‰€æœ‰ç‰¹å¾å·²æå–å®Œæˆï¼Œæ— éœ€å¤„ç†!")
        return
    
    dataloader = DataLoader(
        dataset,
        batch_size=args.batch_size,
        shuffle=False,  # å¿…é¡»Falseä»¥é…åˆæµå¼ä¿å­˜
        num_workers=args.num_workers,
        collate_fn=collate_fn,
        pin_memory=True
    )
    
    # 3. ç‰¹å¾æå–ä¸»å¾ªç¯
    print(f"\n3. å¼€å§‹æå–ç‰¹å¾...")
    print(f"   Batch size: {args.batch_size}")
    print(f"   Num workers: {args.num_workers}")
    
    study_buffer = defaultdict(list)
    saved_count = 0
    error_count = 0
    truncated_count = 0
    
    pbar = tqdm(dataloader, desc="æå–è¿›åº¦", total=len(dataloader))
    
    for batch_samples in pbar:
        if not batch_samples:
            continue
        
        # 3.1 æå–å½“å‰batchç‰¹å¾
        try:
            features_dict = process_batch_raddino(encoder, batch_samples)
        except Exception as e:
            error_count += 1
            print(f"\nâš ï¸  Batchå¤„ç†é”™è¯¯: {e}")
            continue
        
        # 3.2 åŠ å…¥Buffer
        for study_id, items in features_dict.items():
            study_buffer[study_id].extend(items)
        
        # 3.3 æµå¼ä¿å­˜ï¼šæ£€æŸ¥å“ªäº›studyå·²å®Œæˆ
        current_batch_ids = set(features_dict.keys())
        buffer_ids = list(study_buffer.keys())
        
        for sid in buffer_ids:
            if sid not in current_batch_ids:
                # è¯¥studyçš„æ‰€æœ‰å›¾ç‰‡å·²å¤„ç†å®Œ
                views = study_buffer[sid]
                
                # æ‹¼æ¥ç‰¹å¾
                concat_feat, meta = concat_study_features(views)
                
                if concat_feat is not None:
                    try:
                        # ç»Ÿè®¡æˆªæ–­
                        if meta.get('truncated', False):
                            truncated_count += 1
                        
                        # ä¿å­˜ç‰¹å¾ (float16)
                        save_path = os.path.join(output_dir, f"{sid}.npy")
                        np.save(save_path, concat_feat.numpy().astype(np.float16))
                        
                        # ä¿å­˜å…ƒæ•°æ®
                        meta_path = os.path.join(output_dir, f"{sid}_meta.json")
                        with open(meta_path, 'w') as f:
                            json.dump(meta, f)
                        
                        saved_count += 1
                        
                        # æ›´æ–°è¿›åº¦æ¡
                        pbar.set_postfix({
                            'saved': saved_count, 
                            'errors': error_count,
                            'truncated': truncated_count
                        })
                        
                    except Exception as e:
                        error_count += 1
                        print(f"\nâš ï¸  ä¿å­˜é”™è¯¯ {sid}: {e}")
                
                # âœ… ä»å†…å­˜ä¸­åˆ é™¤ï¼Œé‡Šæ”¾ç©ºé—´
                del study_buffer[sid]
    
    # 4. ä¿å­˜å‰©ä½™Bufferä¸­çš„study
    print("\næ­£åœ¨ä¿å­˜å‰©ä½™ç¼“å­˜...")
    for sid, views in study_buffer.items():
        concat_feat, meta = concat_study_features(views)
        if concat_feat is not None:
            try:
                if meta.get('truncated', False):
                    truncated_count += 1
                
                np.save(
                    os.path.join(output_dir, f"{sid}.npy"), 
                    concat_feat.numpy().astype(np.float16)
                )
                with open(os.path.join(output_dir, f"{sid}_meta.json"), 'w') as f:
                    json.dump(meta, f)
                saved_count += 1
            except Exception as e:
                error_count += 1
                print(f"âš ï¸  ä¿å­˜é”™è¯¯ {sid}: {e}")
    
    # 5. å®Œæˆç»Ÿè®¡
    print(f"\n" + "=" * 80)
    print(f"âœ… ç‰¹å¾æå–å®Œæˆ!")
    print("=" * 80)
    print(f"  æˆåŠŸä¿å­˜: {saved_count:,} ä¸ªstudy")
    print(f"  å¤„ç†é”™è¯¯: {error_count:,} ä¸ª")
    
    if truncated_count > 0:
        print(f"  è§†è§’æˆªæ–­: {truncated_count:,} ä¸ª ({truncated_count/saved_count*100:.2f}%) - è¶…è¿‡4è§†è§’")
    
    total_completed = len(existing_studies) + saved_count
    print(f"  æ€»è®¡å®Œæˆ: {total_completed:,} ä¸ª")
    
    print(f"\nğŸ“ è¾“å‡ºç›®å½•: {output_dir}")
    print(f"ğŸ“Š ç‰¹å¾æ ¼å¼: [N*1369, 768] (N â‰¤ 4 views, 518px)")
    print(f"ğŸ’¾ å­˜å‚¨ç²¾åº¦: float16")
    print("=" * 80)


if __name__ == '__main__':
    parser = argparse.ArgumentParser(
        description='RAD-DINO ç‰¹å¾æå–è„šæœ¬ (Final Version)',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ç¤ºä¾‹:
  python visual/visual_processor.py --batch_size 32 --num_workers 4
  
  # æ–­ç‚¹ç»­ä¼ ï¼ˆç›´æ¥é‡æ–°è¿è¡Œå³å¯ï¼‰
  python visual/visual_processor.py
  
é…ç½®è¯´æ˜:
  - batch_size: å»ºè®®16-32 (4090å¯ç”¨32)
  - num_workers: å»ºè®®4-8
  - MAX_VIEWS=4: è¦†ç›–99.93%æ ·æœ¬ï¼Œä¼˜åŒ–è®­ç»ƒæ•ˆç‡
        """
    )
    
    # è·¯å¾„é…ç½®
    parser.add_argument('--csv_file', type=str, 
                        default='data/processed_dataset.csv',
                        help='CSVæ–‡ä»¶è·¯å¾„')
    parser.add_argument('--image_root', type=str, 
                        default='data/mimic-cxr/images',
                        help='å›¾ç‰‡æ ¹ç›®å½•')
    parser.add_argument('--output_dir', type=str, 
                        default='visual/visual_features',
                        help='ç‰¹å¾ä¿å­˜ç›®å½•')
    
    # æ¨¡å‹é…ç½®
    parser.add_argument('--model_name', type=str, 
                        default='microsoft/rad-dino',
                        help='HuggingFaceæ¨¡å‹ID')
    
    # è¿è¡Œé…ç½®
    parser.add_argument('--batch_size', type=int, default=32, 
                        help='æ‰¹å¤§å° (å»ºè®®16-32)')
    parser.add_argument('--num_workers', type=int, default=4, 
                        help='æ•°æ®åŠ è½½çº¿ç¨‹æ•° (å»ºè®®4-8)')
    
    args = parser.parse_args()
    
    main(args)