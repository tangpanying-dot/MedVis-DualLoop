#!/usr/bin/env python3
"""
å¢é‡æ¸…æ´—è„šæœ¬ - å»é™¤å‰©ä½™3.6%çš„å™ªéŸ³
åŸºäºå½“å‰çš„processed_dataset.csvè¿›è¡Œé¢å¤–æ¸…æ´—
"""
import pandas as pd
import re
from tqdm import tqdm

def clean_remaining_noise(
    input_csv='data/processed_dataset.csv',
    output_csv='data/processed_dataset_v17.csv'
):
    """
    åœ¨ç°æœ‰æ¸…æ´—åŸºç¡€ä¸Šï¼Œå»é™¤å‰©ä½™çš„å™ªéŸ³
    """
    
    print("=" * 80)
    print("ğŸ§¹ å¢é‡æ¸…æ´—è„šæœ¬ - å»é™¤å‰©ä½™3.6%å™ªéŸ³")
    print("=" * 80)
    
    # åŠ è½½æ•°æ®
    print(f"\n[1/5] åŠ è½½æ•°æ®: {input_csv}")
    df = pd.read_csv(input_csv)
    print(f"âœ… åŠ è½½ {len(df)} æ¡è®°å½•")
    
    # å®šä¹‰æ¸…æ´—è§„åˆ™
    print("\n[2/5] å®šä¹‰æ¸…æ´—è§„åˆ™...")
    
    # å®šä¹‰éœ€è¦æ¸…æ´—çš„å™ªéŸ³æ¨¡å¼
    noise_patterns = {
        'Dr./åŒ»ç”Ÿç›¸å…³': [
            # å®Œæ•´ç§»é™¤åŒ…å«è¿™äº›çš„å¥å­
            r'[^.]*?(?:conveyed|relayed|discussed|communicated) by Dr\.[^.]*?\.',
            r'[^.]*?findings? (?:were|was) (?:conveyed|relayed|discussed)[^.]*?\.',
            r'[^.]*?by Dr\. \w+ to Dr\. \w+[^.]*?\.',
            r'[^.]*?Dr\. \w+[^.]*?(?:telephone|phone|pager)[^.]*?\.',
        ],
        
        'æ—¶é—´æˆ³ç›¸å…³': [
            r'[^.]*?(?:done|obtained|performed) at \d{2}:\d{2}[^.]*?\.',
            r'[^.]*?(?:examination|study) done at[^.]*?\.',
            r'[^.]*?at \d{2}:\d{2}[^.]*?(?:hours|on)[^.]*?\.',
            r'\d{2}:\d{2}(?:\s+hours)?',  # å•ç‹¬çš„æ—¶é—´æˆ³
        ],
        
        'é€šè®¯ä¿¡æ¯': [
            r'[^.]*?(?:telephone|phone|pager)[^.]*?at \d{2}:\d{2}[^.]*?\.',
            r'[^.]*?pager was placed[^.]*?\.',
            r'[^.]*?min(?:utes)? after[^.]*?\.',
            r'[^.]*?results were conveyed[^.]*?\.',
        ],
        
        'æŠ€æœ¯/è¡Œæ”¿ä¿¡æ¯': [
            r'Analysis is performed in direct\s*',
            r'\d{2}:\d{2}\s+is submitted\.?',
            r'[^.]*?is submitted[^.]*?\.',
            r',\s*MD\s*=\s*CC:\s*DR\..*',
            r'Dictated by[^.]*?\.',
            r'Attending:[^.]*?\.',
            r'Resident:[^.]*?\.',
        ],
        
        'å…¶ä»–å¸¸è§å™ªéŸ³': [
            r'\s+text\s+on\s+at\s*',  # "text on at"
            r'Findings:\s*$',  # ç©ºçš„Findingsæ ‡ç­¾
            r'Impression:\s*$',  # ç©ºçš„Impressionæ ‡ç­¾
            r'\s{2,}',  # å¤šä½™ç©ºæ ¼
        ]
    }
    
    total_patterns = sum(len(patterns) for patterns in noise_patterns.values())
    print(f"   å®šä¹‰äº† {len(noise_patterns)} ç±»å…± {total_patterns} ä¸ªæ¸…æ´—è§„åˆ™")
    
    # æ¸…æ´—å‡½æ•°
    def clean_text(text):
        """æ¸…æ´—å•ä¸ªæ–‡æœ¬"""
        if pd.isna(text) or text == '':
            return text
        
        text = str(text)
        original_text = text
        
        # åº”ç”¨æ‰€æœ‰æ¸…æ´—è§„åˆ™
        for category, patterns in noise_patterns.items():
            for pattern in patterns:
                text = re.sub(pattern, ' ', text, flags=re.IGNORECASE)
        
        # æ¸…ç†å¤šä½™ç©ºæ ¼
        text = re.sub(r'\s+', ' ', text)
        text = text.strip()
        
        # æ¸…ç†å¤šä½™çš„å¥å·
        text = re.sub(r'\.{2,}', '.', text)
        
        # æ¸…ç†å¥å­å¼€å¤´çš„è¿æ¥è¯
        text = re.sub(r'^\s*(?:and|but|or|however|therefore)\s+', '', text, flags=re.IGNORECASE)
        
        return text
    
    # æ¸…æ´—reportåˆ—
    print("\n[3/5] æ¸…æ´—'report'åˆ—...")
    print("   è¿™å¯èƒ½éœ€è¦å‡ åˆ†é’Ÿ...")
    
    cleaned_reports = []
    noise_count = 0
    
    for text in tqdm(df['report'], desc="   å¤„ç†è¿›åº¦"):
        cleaned = clean_text(text)
        cleaned_reports.append(cleaned)
        
        # ç»Ÿè®¡æ˜¯å¦æœ‰å˜åŒ–
        if cleaned != text:
            noise_count += 1
    
    df['report'] = cleaned_reports
    
    print(f"   âœ… å®Œæˆï¼å‘ç°å¹¶æ¸…æ´—äº† {noise_count} æ¡è®°å½• ({noise_count/len(df)*100:.1f}%)")
    
    # å¦‚æœæœ‰findingsåˆ—ï¼Œä¹Ÿæ¸…æ´—
    if 'findings' in df.columns:
        print("\n[4/5] æ¸…æ´—'findings'åˆ—...")
        cleaned_findings = []
        findings_noise_count = 0
        
        for text in tqdm(df['findings'], desc="   å¤„ç†è¿›åº¦"):
            cleaned = clean_text(text)
            cleaned_findings.append(cleaned)
            if cleaned != text:
                findings_noise_count += 1
        
        df['findings'] = cleaned_findings
        print(f"   âœ… å®Œæˆï¼å‘ç°å¹¶æ¸…æ´—äº† {findings_noise_count} æ¡è®°å½• ({findings_noise_count/len(df)*100:.1f}%)")
    else:
        print("\n[4/5] è·³è¿‡findingsåˆ—ï¼ˆä¸å­˜åœ¨ï¼‰")
    
    # ä¿å­˜
    print(f"\n[5/5] ä¿å­˜æ¸…æ´—åçš„æ•°æ®: {output_csv}")
    df.to_csv(output_csv, index=False)
    print(f"   âœ… æˆåŠŸä¿å­˜ {len(df)} æ¡è®°å½•")
    
    # ç»Ÿè®¡
    print("\n" + "=" * 80)
    print("ğŸ“Š æ¸…æ´—ç»Ÿè®¡")
    print("=" * 80)
    print(f"è¾“å…¥æ–‡ä»¶: {input_csv}")
    print(f"è¾“å‡ºæ–‡ä»¶: {output_csv}")
    print(f"æ€»è®°å½•æ•°: {len(df)}")
    print(f"æ¸…æ´—è®°å½•æ•°: {noise_count} ({noise_count/len(df)*100:.1f}%)")
    if 'findings' in df.columns:
        print(f"findingsæ¸…æ´—: {findings_noise_count} ({findings_noise_count/len(df)*100:.1f}%)")
    
    print("\nâœ… æ¸…æ´—å®Œæˆï¼")
    print("\nä¸‹ä¸€æ­¥:")
    print("1. æ£€æŸ¥è¾“å‡ºæ–‡ä»¶: data/processed_dataset_v17.csv")
    print("2. è¿è¡Œè´¨é‡æ£€æŸ¥: python check_training_data.py")
    print("   (è®°å¾—ä¿®æ”¹è„šæœ¬ä¸­çš„csvè·¯å¾„)")
    print("3. å¦‚æœæ»¡æ„ï¼Œå¤‡ä»½åŸæ–‡ä»¶å¹¶æ›¿æ¢:")
    print("   mv data/processed_dataset.csv data/processed_dataset_backup.csv")
    print("   mv data/processed_dataset_v17.csv data/processed_dataset.csv")
    print("4. é‡æ–°è®­ç»ƒStage2: python train_stage2_optimized.py")
    print("=" * 80)

if __name__ == "__main__":
    clean_remaining_noise()